{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('all')\n",
    "import numpy as np # Lineer cebir islemleri\n",
    "import pandas as pd # Verileri okumak için\n",
    "import math\n",
    "import itertools\n",
    "import os    \n",
    "import re, string, timeit\n",
    "from nltk.stem import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from snowballstemmer import TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSetHazirla('ataol')\n",
    "#DataSetHazirla('oveli')\n",
    "#DataSetHazirla('ahmettelli')\n",
    "#DataSetHazirla('cahit')\n",
    "#DataSetHazirla('iozel')\n",
    "#DataSetHazirla('nazim')\n",
    "#DataSetHazirla('necip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "WPT = nltk.WordPunctTokenizer()\n",
    "stop_word_list = nltk.corpus.stopwords.words('turkish')\n",
    "Classes=['aTelli','oveli','ataol','necip','cahit','nazim','iozel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSetHazirla(DosyaAdi):\n",
    "    \n",
    "    all_files = os.listdir(\"sairler/\"+DosyaAdi)   # imagine you're one directory above test dir\n",
    "    print(np.array(all_files))\n",
    "    text=\"\";\n",
    "    for doc in all_files:\n",
    "        with open(\"sairler/\"+DosyaAdi+\"/\"+doc,'r') as source:\n",
    "            data = [ line for line in source ]            \n",
    "            text=text+\" \"+str(data)\n",
    "        print(text)\n",
    "    yeniDosyaAdi=DosyaAdi+\"full.txt\"\n",
    "    with open(yeniDosyaAdi,'w') as target:    \n",
    "        target.write(text) \n",
    "        \n",
    "def readFile(fileName):\n",
    "    with open(fileName,'r') as source:\n",
    "        data = [line for line in source ]\n",
    "        #data=source.read().replace('\\n', '')\n",
    "    return(data)\n",
    "\n",
    "def convert(list): \n",
    "      \n",
    "    # Converting integer list to string list \n",
    "    s = [str(i) for i in list] \n",
    "      \n",
    "    # Join list items using join() \n",
    "    res = \" \".join(s)\n",
    "      \n",
    "    return(res) \n",
    "\n",
    "\n",
    "\n",
    "def norm_docMethod(single_doc):\n",
    "    # TR: Dokümandan belirlenen özel karakterleri ve sayıları at\n",
    "  \n",
    "    single_doc = re.sub(\" \\d+\", \" \", single_doc)\n",
    "    pattern = r\"[{}]\".format(\",.;!:?]\") \n",
    "    single_doc = re.sub(pattern, \"\", single_doc) \n",
    "    # TR: Dokümanı küçük harflere çevir\n",
    "   \n",
    "    single_doc = single_doc.lower()\n",
    "    single_doc = single_doc.strip()\n",
    "    # TR: Dokümanı token'larına ayır\n",
    "  \n",
    "    tokens = WPT.tokenize(single_doc)\n",
    "    # TR: Stop-word listesindeki kelimeler hariç al\n",
    "   \n",
    "    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n",
    "    # TR: Dokümanı tekrar oluştur\n",
    "\n",
    "    single_doc = ' '.join(filtered_tokens)\n",
    "    return single_doc\n",
    "def removeDuplicates(listofElements):\n",
    "    \n",
    "    # Create an empty list to store unique elements\n",
    "    uniqueList = []\n",
    "    \n",
    "    # Iterate over the original list and for each element\n",
    "    # add it to uniqueList, if its not already there.\n",
    "    for elem in listofElements:        \n",
    "        if elem not in uniqueList:\n",
    "            print(elem)\n",
    "            uniqueList.append(elem)\n",
    "    \n",
    "    # Return the list of unique elements        \n",
    "    return uniqueList\n",
    "\n",
    "def prepareDoc(docParam):\n",
    "    \n",
    "    norm_docs = np.vectorize(norm_docMethod) #like magic :)\n",
    "    \n",
    "    docs = np.array(docParam)\n",
    "   \n",
    "    normalized_documents = norm_docs(docs)\n",
    "   \n",
    "    dataout = np.array(normalized_documents)\n",
    "   \n",
    "    return dataout\n",
    "\n",
    "def removeDuplicates(listofElements):\n",
    "    \n",
    "    # Create an empty list to store unique elements\n",
    "    uniqueList = []\n",
    "    \n",
    "    # Iterate over the original list and for each element\n",
    "    # add it to uniqueList, if its not already there.\n",
    "    for elem in listofElements:\n",
    "        if elem not in uniqueList:\n",
    "            uniqueList.append(elem)\n",
    "    \n",
    "    # Return the list of unique elements        \n",
    "    return uniqueList\n",
    "\n",
    "def probFirstStep(data):\n",
    "    #stemmer = SnowballStemmer(\"english\")\n",
    "    turkStem=TurkishStemmer()\n",
    "    \n",
    "    dataout=convert(data)    \n",
    "    dataout = dataout.split()\n",
    "    dataoutstems=[]\n",
    "    wordfreq = []\n",
    "    Pairs=[]\n",
    "    for w in dataout:\n",
    "        \n",
    "        stem=turkStem.stemWord(w) #ekmek\n",
    "        dataoutstems.append(stem)\n",
    "    for w in dataoutstems:\n",
    "        wordfreq.append(dataoutstems.count(w))\n",
    "        #w=print(stemmer.stem(w))\n",
    "    Pairs=list(zip(dataoutstems, wordfreq))    \n",
    "    return Pairs\n",
    "\n",
    "def CalculateProbabilty(PairList):\n",
    "  \n",
    "    lengthOfPair=len(PairList);\n",
    "    Probability=[]\n",
    "    for (a, b) in PairList:\n",
    "        c=b/lengthOfPair\n",
    "        Probability.append(round(c,5))\n",
    "    PairsWithProb=list(zip(PairList, Probability))   \n",
    "    return PairsWithProb\n",
    "\n",
    "def CalculateNBScoreFromList(PairsWithProbList1,size):\n",
    "    ScoreList=[]\n",
    "    PairsClasses=[]\n",
    "    i=0\n",
    "    for dsp in PairsWithProbList1:\n",
    "        length1=len(dsp)\n",
    "        i=PairsWithProbList1.index(dsp)\n",
    "       \n",
    "        print(Classes[i]+\" : \"+str(length1)+\" kelime\")\n",
    "        \n",
    "        score=1\n",
    "        gProb1=length1/size \n",
    "        #score+=math.log(gProb1) \n",
    "        score=score*round(gProb1,5)\n",
    "        score=score*(1/7)#Döküman sayısı\n",
    "        #Her Kelimenin score hesapla\n",
    "        for p in sorted(dsp):\n",
    "            #score+=math.log(p[1])              \n",
    "            score=score*round(p[1],5)\n",
    "   \n",
    "        ScoreList.append(score)\n",
    "        \n",
    "    PCList=list(zip(Classes, ScoreList))\n",
    "    PairsClasses.append(PCList)\n",
    "    return PairsClasses\n",
    "\n",
    "\n",
    "def InsertTestData(DataSet,TestData,cl):\n",
    "    DataSet = np.append(DataSet,testData)\n",
    "    print(Classes[cl]+\" verisetine test verisi eklendi\")\n",
    "    return DataSet;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aTelli verisetine test verisi eklendi\n",
      "oveli verisetine test verisi eklendi\n",
      "ataol verisetine test verisi eklendi\n",
      "necip verisetine test verisi eklendi\n",
      "cahit verisetine test verisi eklendi\n",
      "nazim verisetine test verisi eklendi\n",
      "iozel verisetine test verisi eklendi\n"
     ]
    }
   ],
   "source": [
    "#Veri İşlemleri\n",
    "DataPairList=[]\n",
    "testData=readFile('testData.txt')\n",
    "#Atelli\n",
    "datatelli=readFile('ahmettellifull.txt')\n",
    "datatelli = InsertTestData(datatelli,testData,0) \n",
    "\n",
    "#OVeli\n",
    "dataoveli=readFile('ovelifull.txt')\n",
    "dataoveli = InsertTestData(dataoveli,testData,1)\n",
    "\n",
    "\n",
    "#OVeli\n",
    "dataataol=readFile('ataolfull.txt')\n",
    "dataataol = InsertTestData(dataataol,testData,2)\n",
    "\n",
    "#Necip Fazıl\n",
    "datanecip=readFile('necipfull.txt')\n",
    "datanecip = InsertTestData(datanecip,testData,3)\n",
    "\n",
    "#Cahit sıtkı Tarancı\n",
    "datacahit=readFile('cahitfull.txt')\n",
    "datacahit = InsertTestData(datacahit,testData,4)\n",
    "\n",
    "#Nazım Hikmet\n",
    "datanazim=readFile('nazimfull.txt')\n",
    "datanazim = InsertTestData(datanazim,testData,5)\n",
    "\n",
    "#Nazım Hikmet\n",
    "dataozel=readFile('iozelfull.txt')\n",
    "dataozel = InsertTestData(dataozel,testData,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 850\n",
      "    Kelime Kökü-Sıklık  Frekans\n",
      "0              (aç, 9)  0.01059\n",
      "1      (tutanakçıs, 2)  0.00235\n",
      "2         (anlatıp, 1)  0.00118\n",
      "3           (durur, 4)  0.00471\n",
      "4             (aşk, 3)  0.00353\n",
      "5         (ayrılık, 6)  0.00706\n",
      "6           (desta, 1)  0.00118\n",
      "7       (yalnızlık, 7)  0.00824\n",
      "8             (ömr, 6)  0.00706\n",
      "9           (göçep, 1)  0.00118\n",
      "10          (gezgi, 1)  0.00118\n",
      "11          (aylak, 1)  0.00118\n",
      "12          (birmi, 1)  0.00118\n",
      "13            (akl, 1)  0.00118\n",
      "14        (gelmedi, 1)  0.00118\n",
      "15           (bir, 68)  0.08000\n",
      "16        (çingene, 2)  0.00235\n",
      "17          (biliç, 1)  0.00118\n",
      "18           (ayni, 1)  0.00118\n",
      "19             (şe, 1)  0.00118\n",
      "20         (bildik, 2)  0.00235\n",
      "21     (serserilik, 1)  0.00118\n",
      "22        (masalcı, 1)  0.00118\n",
      "23         (yaşadı, 1)  0.00118\n",
      "24          (büyük, 2)  0.00235\n",
      "25        (serüven, 1)  0.00118\n",
      "26       (yolculuk, 1)  0.00118\n",
      "27          (tarih, 1)  0.00118\n",
      "28             (be, 7)  0.00824\n",
      "29            (acı, 3)  0.00353\n",
      "..                 ...      ...\n",
      "820           (çok, 1)  0.00118\n",
      "821       (vermedi, 1)  0.00118\n",
      "822         (terki, 1)  0.00118\n",
      "823            (al, 1)  0.00118\n",
      "824        (öpücük, 1)  0.00118\n",
      "825       (koşuyor, 1)  0.00118\n",
      "826        (iyotlu, 1)  0.00118\n",
      "827           (ayr, 1)  0.00118\n",
      "828         (doğru, 1)  0.00118\n",
      "829        (kolkol, 1)  0.00118\n",
      "830        (taşıdı, 1)  0.00118\n",
      "831     (taşıyamaz, 1)  0.00118\n",
      "832         (batık, 1)  0.00118\n",
      "833        (sandal, 1)  0.00118\n",
      "834  (yalnızlığıbu, 1)  0.00118\n",
      "835      (gelincik, 1)  0.00118\n",
      "836         (çalma, 1)  0.00118\n",
      "837        (onarma, 1)  0.00118\n",
      "838        (kalkma, 1)  0.00118\n",
      "839    (kaybedilme, 1)  0.00118\n",
      "840         (değer, 1)  0.00118\n",
      "841    (bitirilmiş, 1)  0.00118\n",
      "842      (memleket, 2)  0.00235\n",
      "843             (i, 1)  0.00118\n",
      "844             (̇, 1)  0.00118\n",
      "845          (ster, 1)  0.00118\n",
      "846          (mavi, 1)  0.00118\n",
      "847         (yeşil, 1)  0.00118\n",
      "848           (tar, 1)  0.00118\n",
      "849           (sar, 1)  0.00118\n",
      "\n",
      "[850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "DataSetSize=0 #Kelime sayısı\n",
    "DataPairList=[]\n",
    "Pairs=[]\n",
    "dataTelli=prepareDoc(datatelli)#hazırlık\n",
    "Pairs=probFirstStep(dataTelli)\n",
    "Atelli=removeDuplicates(Pairs)\n",
    "PairsWithProbAtelli=CalculateProbabilty(Atelli)\n",
    "\n",
    "DataPairList.append(Atelli)\n",
    "DataSetSize=DataSetSize+len(Atelli)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbAtelli, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 1616\n"
     ]
    }
   ],
   "source": [
    "dataOveli=prepareDoc(dataoveli)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataOveli)\n",
    "dataOveli=removeDuplicates(Pairs)\n",
    "PairsWithProbdataOveli=CalculateProbabilty(dataOveli)\n",
    "\n",
    "DataPairList.append(dataOveli)\n",
    "DataSetSize=DataSetSize+len(dataOveli)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 2721\n",
      "    Kelime Kökü-Sıklık  Frekans\n",
      "0              (aç, 9)  0.01059\n",
      "1      (tutanakçıs, 2)  0.00235\n",
      "2         (anlatıp, 1)  0.00118\n",
      "3           (durur, 4)  0.00471\n",
      "4             (aşk, 3)  0.00353\n",
      "5         (ayrılık, 6)  0.00706\n",
      "6           (desta, 1)  0.00118\n",
      "7       (yalnızlık, 7)  0.00824\n",
      "8             (ömr, 6)  0.00706\n",
      "9           (göçep, 1)  0.00118\n",
      "10          (gezgi, 1)  0.00118\n",
      "11          (aylak, 1)  0.00118\n",
      "12          (birmi, 1)  0.00118\n",
      "13            (akl, 1)  0.00118\n",
      "14        (gelmedi, 1)  0.00118\n",
      "15           (bir, 68)  0.08000\n",
      "16        (çingene, 2)  0.00235\n",
      "17          (biliç, 1)  0.00118\n",
      "18           (ayni, 1)  0.00118\n",
      "19             (şe, 1)  0.00118\n",
      "20         (bildik, 2)  0.00235\n",
      "21     (serserilik, 1)  0.00118\n",
      "22        (masalcı, 1)  0.00118\n",
      "23         (yaşadı, 1)  0.00118\n",
      "24          (büyük, 2)  0.00235\n",
      "25        (serüven, 1)  0.00118\n",
      "26       (yolculuk, 1)  0.00118\n",
      "27          (tarih, 1)  0.00118\n",
      "28             (be, 7)  0.00824\n",
      "29            (acı, 3)  0.00353\n",
      "..                 ...      ...\n",
      "820           (çok, 1)  0.00118\n",
      "821       (vermedi, 1)  0.00118\n",
      "822         (terki, 1)  0.00118\n",
      "823            (al, 1)  0.00118\n",
      "824        (öpücük, 1)  0.00118\n",
      "825       (koşuyor, 1)  0.00118\n",
      "826        (iyotlu, 1)  0.00118\n",
      "827           (ayr, 1)  0.00118\n",
      "828         (doğru, 1)  0.00118\n",
      "829        (kolkol, 1)  0.00118\n",
      "830        (taşıdı, 1)  0.00118\n",
      "831     (taşıyamaz, 1)  0.00118\n",
      "832         (batık, 1)  0.00118\n",
      "833        (sandal, 1)  0.00118\n",
      "834  (yalnızlığıbu, 1)  0.00118\n",
      "835      (gelincik, 1)  0.00118\n",
      "836         (çalma, 1)  0.00118\n",
      "837        (onarma, 1)  0.00118\n",
      "838        (kalkma, 1)  0.00118\n",
      "839    (kaybedilme, 1)  0.00118\n",
      "840         (değer, 1)  0.00118\n",
      "841    (bitirilmiş, 1)  0.00118\n",
      "842      (memleket, 2)  0.00235\n",
      "843             (i, 1)  0.00118\n",
      "844             (̇, 1)  0.00118\n",
      "845          (ster, 1)  0.00118\n",
      "846          (mavi, 1)  0.00118\n",
      "847         (yeşil, 1)  0.00118\n",
      "848           (tar, 1)  0.00118\n",
      "849           (sar, 1)  0.00118\n",
      "\n",
      "[850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataAtaol=prepareDoc(dataataol)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataAtaol)\n",
    "dataAtaol=removeDuplicates(Pairs)\n",
    "PairsWithProbDataAtaol=CalculateProbabilty(dataAtaol)\n",
    "\n",
    "DataPairList.append(dataAtaol)\n",
    "DataSetSize=DataSetSize+len(dataAtaol)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbAtelli, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri\n",
    "#print(PairsWithProbDataAtaol) #kelime, frekansı, olasılık değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 3809\n",
      "    Kelime Kökü-Sıklık  Frekans\n",
      "0              (aç, 9)  0.01059\n",
      "1      (tutanakçıs, 2)  0.00235\n",
      "2         (anlatıp, 1)  0.00118\n",
      "3           (durur, 4)  0.00471\n",
      "4             (aşk, 3)  0.00353\n",
      "5         (ayrılık, 6)  0.00706\n",
      "6           (desta, 1)  0.00118\n",
      "7       (yalnızlık, 7)  0.00824\n",
      "8             (ömr, 6)  0.00706\n",
      "9           (göçep, 1)  0.00118\n",
      "10          (gezgi, 1)  0.00118\n",
      "11          (aylak, 1)  0.00118\n",
      "12          (birmi, 1)  0.00118\n",
      "13            (akl, 1)  0.00118\n",
      "14        (gelmedi, 1)  0.00118\n",
      "15           (bir, 68)  0.08000\n",
      "16        (çingene, 2)  0.00235\n",
      "17          (biliç, 1)  0.00118\n",
      "18           (ayni, 1)  0.00118\n",
      "19             (şe, 1)  0.00118\n",
      "20         (bildik, 2)  0.00235\n",
      "21     (serserilik, 1)  0.00118\n",
      "22        (masalcı, 1)  0.00118\n",
      "23         (yaşadı, 1)  0.00118\n",
      "24          (büyük, 2)  0.00235\n",
      "25        (serüven, 1)  0.00118\n",
      "26       (yolculuk, 1)  0.00118\n",
      "27          (tarih, 1)  0.00118\n",
      "28             (be, 7)  0.00824\n",
      "29            (acı, 3)  0.00353\n",
      "..                 ...      ...\n",
      "820           (çok, 1)  0.00118\n",
      "821       (vermedi, 1)  0.00118\n",
      "822         (terki, 1)  0.00118\n",
      "823            (al, 1)  0.00118\n",
      "824        (öpücük, 1)  0.00118\n",
      "825       (koşuyor, 1)  0.00118\n",
      "826        (iyotlu, 1)  0.00118\n",
      "827           (ayr, 1)  0.00118\n",
      "828         (doğru, 1)  0.00118\n",
      "829        (kolkol, 1)  0.00118\n",
      "830        (taşıdı, 1)  0.00118\n",
      "831     (taşıyamaz, 1)  0.00118\n",
      "832         (batık, 1)  0.00118\n",
      "833        (sandal, 1)  0.00118\n",
      "834  (yalnızlığıbu, 1)  0.00118\n",
      "835      (gelincik, 1)  0.00118\n",
      "836         (çalma, 1)  0.00118\n",
      "837        (onarma, 1)  0.00118\n",
      "838        (kalkma, 1)  0.00118\n",
      "839    (kaybedilme, 1)  0.00118\n",
      "840         (değer, 1)  0.00118\n",
      "841    (bitirilmiş, 1)  0.00118\n",
      "842      (memleket, 2)  0.00235\n",
      "843             (i, 1)  0.00118\n",
      "844             (̇, 1)  0.00118\n",
      "845          (ster, 1)  0.00118\n",
      "846          (mavi, 1)  0.00118\n",
      "847         (yeşil, 1)  0.00118\n",
      "848           (tar, 1)  0.00118\n",
      "849           (sar, 1)  0.00118\n",
      "\n",
      "[850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataNecip=prepareDoc(datanecip)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataNecip)\n",
    "dataNecip=removeDuplicates(Pairs)\n",
    "PairsWithProbDataAtaol=CalculateProbabilty(dataNecip)\n",
    "\n",
    "DataPairList.append(dataNecip)\n",
    "DataSetSize=DataSetSize+len(dataNecip)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbAtelli, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri\n",
    "#print(PairsWithProbDataAtaol) #kelime, frekansı, olasılık değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 4334\n",
      "    Kelime Kökü-Sıklık  Frekans\n",
      "0              (aç, 9)  0.01059\n",
      "1      (tutanakçıs, 2)  0.00235\n",
      "2         (anlatıp, 1)  0.00118\n",
      "3           (durur, 4)  0.00471\n",
      "4             (aşk, 3)  0.00353\n",
      "5         (ayrılık, 6)  0.00706\n",
      "6           (desta, 1)  0.00118\n",
      "7       (yalnızlık, 7)  0.00824\n",
      "8             (ömr, 6)  0.00706\n",
      "9           (göçep, 1)  0.00118\n",
      "10          (gezgi, 1)  0.00118\n",
      "11          (aylak, 1)  0.00118\n",
      "12          (birmi, 1)  0.00118\n",
      "13            (akl, 1)  0.00118\n",
      "14        (gelmedi, 1)  0.00118\n",
      "15           (bir, 68)  0.08000\n",
      "16        (çingene, 2)  0.00235\n",
      "17          (biliç, 1)  0.00118\n",
      "18           (ayni, 1)  0.00118\n",
      "19             (şe, 1)  0.00118\n",
      "20         (bildik, 2)  0.00235\n",
      "21     (serserilik, 1)  0.00118\n",
      "22        (masalcı, 1)  0.00118\n",
      "23         (yaşadı, 1)  0.00118\n",
      "24          (büyük, 2)  0.00235\n",
      "25        (serüven, 1)  0.00118\n",
      "26       (yolculuk, 1)  0.00118\n",
      "27          (tarih, 1)  0.00118\n",
      "28             (be, 7)  0.00824\n",
      "29            (acı, 3)  0.00353\n",
      "..                 ...      ...\n",
      "820           (çok, 1)  0.00118\n",
      "821       (vermedi, 1)  0.00118\n",
      "822         (terki, 1)  0.00118\n",
      "823            (al, 1)  0.00118\n",
      "824        (öpücük, 1)  0.00118\n",
      "825       (koşuyor, 1)  0.00118\n",
      "826        (iyotlu, 1)  0.00118\n",
      "827           (ayr, 1)  0.00118\n",
      "828         (doğru, 1)  0.00118\n",
      "829        (kolkol, 1)  0.00118\n",
      "830        (taşıdı, 1)  0.00118\n",
      "831     (taşıyamaz, 1)  0.00118\n",
      "832         (batık, 1)  0.00118\n",
      "833        (sandal, 1)  0.00118\n",
      "834  (yalnızlığıbu, 1)  0.00118\n",
      "835      (gelincik, 1)  0.00118\n",
      "836         (çalma, 1)  0.00118\n",
      "837        (onarma, 1)  0.00118\n",
      "838        (kalkma, 1)  0.00118\n",
      "839    (kaybedilme, 1)  0.00118\n",
      "840         (değer, 1)  0.00118\n",
      "841    (bitirilmiş, 1)  0.00118\n",
      "842      (memleket, 2)  0.00235\n",
      "843             (i, 1)  0.00118\n",
      "844             (̇, 1)  0.00118\n",
      "845          (ster, 1)  0.00118\n",
      "846          (mavi, 1)  0.00118\n",
      "847         (yeşil, 1)  0.00118\n",
      "848           (tar, 1)  0.00118\n",
      "849           (sar, 1)  0.00118\n",
      "\n",
      "[850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataCahit=prepareDoc(datacahit)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataCahit)\n",
    "dataCahit=removeDuplicates(Pairs)\n",
    "PairsWithProbDataCahit=CalculateProbabilty(dataCahit)\n",
    "\n",
    "DataPairList.append(dataCahit)\n",
    "DataSetSize=DataSetSize+len(dataCahit)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbAtelli, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 5545\n",
      "     Kelime Kökü-Sıklık  Frekans\n",
      "0               (ek, 2)  0.00165\n",
      "1              (dak, 3)  0.00248\n",
      "2              (üst, 7)  0.00578\n",
      "3             (akşa, 2)  0.00165\n",
      "4            (güneş, 3)  0.00248\n",
      "5            (yüklü, 3)  0.00248\n",
      "6              (ola, 3)  0.00248\n",
      "7             (bir, 98)  0.08092\n",
      "8            (bulut, 6)  0.00495\n",
      "9             (var, 14)  0.01156\n",
      "10            (bugu, 3)  0.00248\n",
      "11          (sensiz, 1)  0.00083\n",
      "12             (yar, 1)  0.00083\n",
      "13            (yarı, 1)  0.00083\n",
      "14          (dünyas, 1)  0.00083\n",
      "15            (geç, 12)  0.00991\n",
      "16           (biraz, 2)  0.00165\n",
      "17            (açar, 2)  0.00165\n",
      "18          (kırmız, 5)  0.00413\n",
      "19        (gecesefa, 1)  0.00083\n",
      "20           (taşır, 1)  0.00083\n",
      "21            (hava, 2)  0.00165\n",
      "22          (sessiz, 1)  0.00083\n",
      "23           (cesur, 1)  0.00083\n",
      "24           (kanat, 1)  0.00083\n",
      "25            (vata, 1)  0.00083\n",
      "26         (ayrılık, 2)  0.00165\n",
      "27         (benzeye, 1)  0.00083\n",
      "28             (aşk, 2)  0.00165\n",
      "29           (mönüs, 1)  0.00083\n",
      "...                 ...      ...\n",
      "1181       (şaşırıp, 1)  0.00083\n",
      "1182         (bırak, 1)  0.00083\n",
      "1183        (düşmek, 1)  0.00083\n",
      "1184       (ürperme, 1)  0.00083\n",
      "1185       (ürkerek, 1)  0.00083\n",
      "1186        (sandal, 1)  0.00083\n",
      "1187          (çift, 1)  0.00083\n",
      "1188          (şekl, 1)  0.00083\n",
      "1189     (yalnızlık, 1)  0.00083\n",
      "1190     (birdenbir, 1)  0.00083\n",
      "1191      (kahrolup, 1)  0.00083\n",
      "1192            (du, 1)  0.00083\n",
      "1193   (insansızlık, 1)  0.00083\n",
      "1194         (yükle, 1)  0.00083\n",
      "1195         (kırıl, 1)  0.00083\n",
      "1196    (sürüklüyor, 1)  0.00083\n",
      "1197          (mümk, 1)  0.00083\n",
      "1198           (lkö, 1)  0.00083\n",
      "1199        (küfret, 1)  0.00083\n",
      "1200          (elha, 1)  0.00083\n",
      "1201        (okumak, 1)  0.00083\n",
      "1202        (eğilip, 1)  0.00083\n",
      "1203        (okşadı, 1)  0.00083\n",
      "1204       (mübarek, 1)  0.00083\n",
      "1205         (malûm, 1)  0.00083\n",
      "1206        (olmadı, 1)  0.00083\n",
      "1207        (âkıbet, 1)  0.00083\n",
      "1208          (ster, 1)  0.00083\n",
      "1209         (ister, 1)  0.00083\n",
      "1210           (tar, 1)  0.00083\n",
      "\n",
      "[1211 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataNazim=prepareDoc(datanazim)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataNazim)\n",
    "dataNazim=removeDuplicates(Pairs)\n",
    "PairsWithProbDataNazim=CalculateProbabilty(dataNazim)\n",
    "\n",
    "DataPairList.append(dataNazim)\n",
    "DataSetSize=DataSetSize+len(dataNazim)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbDataNazim, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kelime Sayısı 7598\n",
      "     Kelime Kökü-Sıklık  Frekans\n",
      "0               (aç, 4)  0.00195\n",
      "1        (omuzlanış, 1)  0.00049\n",
      "2            (kadı, 10)  0.00487\n",
      "3            (bir, 170)  0.08281\n",
      "4          (gürültü, 1)  0.00049\n",
      "5          (sapladı, 1)  0.00049\n",
      "6               (ev, 5)  0.00244\n",
      "7          (tıkırtı, 3)  0.00146\n",
      "8            (tıkır, 1)  0.00049\n",
      "9          (kahkaha, 2)  0.00097\n",
      "10        (düşürdük, 1)  0.00049\n",
      "11           (çiçek, 6)  0.00292\n",
      "12        (bulamadı, 2)  0.00097\n",
      "13        (fırtınal, 2)  0.00097\n",
      "14            (geç, 14)  0.00682\n",
      "15           (bomba, 2)  0.00097\n",
      "16              (bö, 2)  0.00097\n",
      "17            (ses, 13)  0.00633\n",
      "18           (savaş, 1)  0.00049\n",
      "19        (alaboras, 1)  0.00049\n",
      "20         (yaşamak, 9)  0.00438\n",
      "21       (aldırmadı, 1)  0.00049\n",
      "22          (çocuk, 23)  0.01120\n",
      "23             (düş, 4)  0.00195\n",
      "24          (markut, 1)  0.00049\n",
      "25          (kurbak, 1)  0.00049\n",
      "26        (zıplıyor, 2)  0.00097\n",
      "27          (yaşama, 2)  0.00097\n",
      "28           (hergi, 4)  0.00195\n",
      "29       (eksiliyor, 1)  0.00049\n",
      "...                 ...      ...\n",
      "2023      (armonika, 2)  0.00097\n",
      "2024        (mazgal, 1)  0.00049\n",
      "2025      (fırlamak, 1)  0.00049\n",
      "2026          (kama, 1)  0.00049\n",
      "2027      (saplamak, 1)  0.00049\n",
      "2028      (coşarlık, 1)  0.00049\n",
      "2029       (çatırdı, 1)  0.00049\n",
      "2030         (ovmak, 1)  0.00049\n",
      "2031       (çatlaya, 1)  0.00049\n",
      "2032      (hengames, 1)  0.00049\n",
      "2033     (gülümseme, 1)  0.00049\n",
      "2034            (ür, 1)  0.00049\n",
      "2035      (kaldırma, 1)  0.00049\n",
      "2036      (derbeder, 1)  0.00049\n",
      "2037          (okul, 1)  0.00049\n",
      "2038         (çanta, 1)  0.00049\n",
      "2039       (sevişli, 1)  0.00049\n",
      "2040       (girilir, 1)  0.00049\n",
      "2041      (boğulduk, 1)  0.00049\n",
      "2042       (armonik, 1)  0.00049\n",
      "2043         (seğir, 1)  0.00049\n",
      "2044         (coşar, 1)  0.00049\n",
      "2045       (yekinme, 1)  0.00049\n",
      "2046         (hanoy, 1)  0.00049\n",
      "2047     (uçaksavar, 1)  0.00049\n",
      "2048      (memleket, 2)  0.00097\n",
      "2049          (ster, 1)  0.00049\n",
      "2050         (yeşil, 1)  0.00049\n",
      "2051           (tar, 1)  0.00049\n",
      "2052           (sar, 1)  0.00049\n",
      "\n",
      "[2053 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataOzel=prepareDoc(dataozel)\n",
    "Pairs=[]\n",
    "Pairs=probFirstStep(dataOzel)\n",
    "dataOzel=removeDuplicates(Pairs)\n",
    "PairsWithProbDataOzel=CalculateProbabilty(dataOzel)\n",
    "\n",
    "DataPairList.append(dataOzel)\n",
    "DataSetSize=DataSetSize+len(dataOzel)\n",
    "print(\"Toplam kelime Sayısı \"+str(DataSetSize))\n",
    "df = pd.DataFrame(PairsWithProbDataOzel, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "print(df) #kelime, frekansı, olasılık değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aTelli : 850 kelime\n",
      "oveli : 766 kelime\n",
      "ataol : 1105 kelime\n",
      "necip : 1088 kelime\n",
      "cahit : 525 kelime\n",
      "nazim : 1211 kelime\n",
      "iozel : 2053 kelime\n",
      "  Kelime Kökü-Sıklık        Frekans\n",
      "0             aTelli  8.558389e+107\n",
      "1              oveli  3.583964e+110\n",
      "2              ataol  5.778576e+199\n",
      "3              necip  1.342595e+151\n",
      "4              cahit   5.084034e+74\n",
      "5              nazim  1.451331e+200\n",
      "6              iozel  1.057828e+273\n"
     ]
    }
   ],
   "source": [
    "PairsWithProbData=CalculateNBScoreFromList(DataPairList,DataSetSize)\n",
    "for item in PairsWithProbData:   \n",
    "    df = pd.DataFrame(item, columns=[\"Kelime Kökü-Sıklık\", \"Frekans\"]) \n",
    "    print(df) #kelime, frekansı, olasılık değeri\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
